"""
Assistant IA conversationnel pour l'analyse BIM
Permet de dialoguer avec les fichiers IFC via un chatbot intelligent
"""

import json
import logging
from typing import Dict, List, Any, Optional
from pathlib import Path
try:
    # Option 1: Ollama (RecommandÃ©)
    from langchain.llms import Ollama
    from langchain.embeddings import OllamaEmbeddings
    OLLAMA_AVAILABLE = True
except ImportError:
    OLLAMA_AVAILABLE = False

try:
    # Option 2: Hugging Face Transformers
    from langchain.llms import HuggingFacePipeline
    from langchain.embeddings import HuggingFaceEmbeddings
    from transformers import pipeline
    HUGGINGFACE_AVAILABLE = True
except ImportError:
    HUGGINGFACE_AVAILABLE = False

from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.schema import Document
import os
from dotenv import load_dotenv

from ifc_analyzer import IFCAnalyzer
from anomaly_detector import IFCAnomalyDetector

# Charger les variables d'environnement
load_dotenv()

logger = logging.getLogger(__name__)

class BIMAssistant:
    """Assistant IA pour l'analyse conversationnelle de fichiers BIM"""

    def __init__(self, model_type: str = "ollama", model_name: str = "llama3.1:8b"):
        """
        Initialise l'assistant BIM avec diffÃ©rents backends IA

        Args:
            model_type: Type de modÃ¨le ("ollama", "huggingface", "openai")
            model_name: Nom du modÃ¨le Ã  utiliser
        """
        self.model_type = model_type
        self.model_name = model_name

        # Initialiser le LLM selon le type choisi
        self.llm, self.embeddings = self._initialize_llm_and_embeddings()

        # MÃ©moire conversationnelle
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            output_key="answer"
        )
        
        # Base de connaissances vectorielle
        self.vectorstore = None
        self.qa_chain = None
        
        # DonnÃ©es du modÃ¨le actuel
        self.current_ifc_data = None
        self.current_file_path = None
        
        # Contexte BIM spÃ©cialisÃ©
        self.bim_context = self._create_bim_context()

    def _initialize_llm_and_embeddings(self):
        """Initialise le LLM et les embeddings selon le type choisi"""

        if self.model_type == "ollama" and OLLAMA_AVAILABLE:
            try:
                # VÃ©rifier qu'Ollama est disponible
                import requests
                response = requests.get("http://localhost:11434/api/tags", timeout=5)
                if response.status_code == 200:
                    logger.info(f"Utilisation d'Ollama avec le modÃ¨le {self.model_name}")
                    llm = Ollama(
                        model=self.model_name,
                        temperature=0.1,
                        base_url="http://localhost:11434"
                    )
                    embeddings = OllamaEmbeddings(
                        model=self.model_name,
                        base_url="http://localhost:11434"
                    )
                    return llm, embeddings
                else:
                    logger.warning("Ollama non disponible, passage Ã  Hugging Face")
            except Exception as e:
                logger.warning(f"Erreur Ollama: {e}, passage Ã  Hugging Face")

        if self.model_type == "huggingface" and HUGGINGFACE_AVAILABLE:
            try:
                logger.info("Utilisation de Hugging Face Transformers")

                # Utiliser un modÃ¨le lÃ©ger et performant
                model_name = "microsoft/DialoGPT-medium"  # Ou "distilbert-base-uncased"

                # Pipeline pour la gÃ©nÃ©ration de texte
                pipe = pipeline(
                    "text-generation",
                    model=model_name,
                    max_length=512,
                    temperature=0.1,
                    do_sample=True
                )

                llm = HuggingFacePipeline(pipeline=pipe)
                embeddings = HuggingFaceEmbeddings(
                    model_name="sentence-transformers/all-MiniLM-L6-v2"
                )

                return llm, embeddings

            except Exception as e:
                logger.warning(f"Erreur Hugging Face: {e}")

        # Fallback: Assistant simple sans LLM externe
        logger.warning("Aucun LLM externe disponible, utilisation du mode simple")
        return None, None

    def _create_bim_context(self) -> str:
        """CrÃ©e le contexte spÃ©cialisÃ© BIM pour l'assistant"""
        return """
        Vous Ãªtes un assistant expert en BIM (Building Information Modeling) et en analyse de fichiers IFC.
        
        Votre rÃ´le est d'aider les utilisateurs Ã  comprendre et analyser leurs modÃ¨les BIM en rÃ©pondant Ã  leurs questions
        de maniÃ¨re claire et prÃ©cise.
        
        Connaissances spÃ©cialisÃ©es:
        - Format IFC (Industry Foundation Classes) et ses entitÃ©s
        - Ã‰lÃ©ments de construction: murs (IfcWall), dalles (IfcSlab), poutres (IfcBeam), colonnes (IfcColumn)
        - Espaces (IfcSpace) et leur analyse
        - Ouvertures: portes (IfcDoor), fenÃªtres (IfcWindow)
        - MatÃ©riaux et propriÃ©tÃ©s des Ã©lÃ©ments
        - MÃ©triques de bÃ¢timent: surfaces, volumes, ratios
        - DÃ©tection d'anomalies et problÃ¨mes de qualitÃ© BIM
        - Classification de bÃ¢timents
        
        Instructions:
        1. RÃ©pondez toujours en franÃ§ais
        2. Soyez prÃ©cis et technique quand nÃ©cessaire, mais restez accessible
        3. Utilisez les donnÃ©es du modÃ¨le IFC chargÃ© pour rÃ©pondre aux questions
        4. Si vous ne trouvez pas l'information dans les donnÃ©es, dites-le clairement
        5. Proposez des analyses complÃ©mentaires quand c'est pertinent
        6. Expliquez les termes techniques BIM si nÃ©cessaire
        """
    
    def load_ifc_model(self, ifc_file_path: str) -> Dict[str, Any]:
        """
        Charge un modÃ¨le IFC et prÃ©pare l'assistant pour les questions
        
        Args:
            ifc_file_path: Chemin vers le fichier IFC
            
        Returns:
            Dictionnaire avec le rÃ©sumÃ© du chargement
        """
        try:
            logger.info(f"Chargement du modÃ¨le IFC: {ifc_file_path}")
            
            # Analyser le fichier IFC
            analyzer = IFCAnalyzer(ifc_file_path)
            self.current_ifc_data = analyzer.generate_full_analysis()
            self.current_file_path = ifc_file_path
            
            # DÃ©tecter les anomalies
            anomaly_detector = IFCAnomalyDetector(ifc_file_path)
            anomalies = anomaly_detector.detect_all_anomalies()
            anomaly_summary = anomaly_detector.get_anomaly_summary()
            
            # Ajouter les anomalies aux donnÃ©es
            self.current_ifc_data["anomalies"] = {
                "anomalies_list": [anomaly.__dict__ for anomaly in anomalies],
                "summary": anomaly_summary
            }
            
            # CrÃ©er la base de connaissances vectorielle
            self._create_vector_store()
            
            # CrÃ©er la chaÃ®ne de Q&A
            self._create_qa_chain()
            
            # RÃ©sumÃ© du chargement
            project_info = self.current_ifc_data.get("project_info", {})
            metrics = self.current_ifc_data.get("building_metrics", {})
            
            summary = {
                "status": "success",
                "file_name": Path(ifc_file_path).name,
                "project_name": project_info.get("project_name", "Non dÃ©fini"),
                "building_name": project_info.get("building_name", "Non dÃ©fini"),
                "total_elements": project_info.get("total_elements", 0),
                "total_storeys": metrics.get("storeys", {}).get("total_storeys", 0),
                "total_spaces": metrics.get("spaces", {}).get("total_spaces", 0),
                "total_anomalies": anomaly_summary.get("total_anomalies", 0),
                "file_size_mb": round(project_info.get("file_size_mb", 0), 2)
            }
            
            logger.info("ModÃ¨le IFC chargÃ© avec succÃ¨s")
            return summary
            
        except Exception as e:
            logger.error(f"Erreur lors du chargement du modÃ¨le IFC: {e}")
            raise
    
    def _create_vector_store(self):
        """CrÃ©e la base de connaissances vectorielle Ã  partir des donnÃ©es IFC"""
        if not self.current_ifc_data:
            raise ValueError("Aucun modÃ¨le IFC chargÃ©")
        
        # Convertir les donnÃ©es IFC en documents textuels
        documents = []
        
        # Informations du projet
        project_info = self.current_ifc_data.get("project_info", {})
        project_text = f"""
        Informations du projet:
        - Nom du projet: {project_info.get('project_name', 'Non dÃ©fini')}
        - Nom du bÃ¢timent: {project_info.get('building_name', 'Non dÃ©fini')}
        - Description: {project_info.get('building_description', 'Non dÃ©fini')}
        - Schema IFC: {project_info.get('schema', 'Non dÃ©fini')}
        - Nombre total d'Ã©lÃ©ments: {project_info.get('total_elements', 0)}
        - Taille du fichier: {project_info.get('file_size_mb', 0):.2f} MB
        """
        documents.append(Document(page_content=project_text, metadata={"type": "project_info"}))
        
        # MÃ©triques du bÃ¢timent
        metrics = self.current_ifc_data.get("building_metrics", {})
        
        # Surfaces
        surfaces = metrics.get("surfaces", {})
        surfaces_text = f"""
        Surfaces du bÃ¢timent:
        - Surface totale des planchers: {surfaces.get('total_floor_area', 0):.2f} mÂ²
        - Surface totale des murs: {surfaces.get('total_wall_area', 0):.2f} mÂ²
        - Surface totale des fenÃªtres: {surfaces.get('total_window_area', 0):.2f} mÂ²
        - Surface totale des portes: {surfaces.get('total_door_area', 0):.2f} mÂ²
        - Surface totale des toitures: {surfaces.get('total_roof_area', 0):.2f} mÂ²
        """
        documents.append(Document(page_content=surfaces_text, metadata={"type": "surfaces"}))
        
        # Volumes
        volumes = metrics.get("volumes", {})
        volumes_text = f"""
        Volumes du bÃ¢timent:
        - Volume total des espaces: {volumes.get('total_space_volume', 0):.2f} mÂ³
        - Volume structurel: {volumes.get('structural_volume', 0):.2f} mÂ³
        - Volume total du bÃ¢timent: {volumes.get('total_building_volume', 0):.2f} mÂ³
        """
        documents.append(Document(page_content=volumes_text, metadata={"type": "volumes"}))
        
        # Ã‰tages
        storeys = metrics.get("storeys", {})
        storeys_text = f"""
        Ã‰tages du bÃ¢timent:
        - Nombre total d'Ã©tages: {storeys.get('total_storeys', 0)}
        """
        
        for storey in storeys.get("storey_details", []):
            storeys_text += f"""
        - Ã‰tage '{storey.get('name', 'Sans nom')}': 
          Ã‰lÃ©vation: {storey.get('elevation', 'Non dÃ©finie')} m
          Nombre d'Ã©lÃ©ments: {storey.get('elements_count', 0)}
          Description: {storey.get('description', 'Aucune')}
            """
        
        documents.append(Document(page_content=storeys_text, metadata={"type": "storeys"}))
        
        # Espaces
        spaces = metrics.get("spaces", {})
        spaces_text = f"""
        Espaces du bÃ¢timent:
        - Nombre total d'espaces: {spaces.get('total_spaces', 0)}
        - Types d'espaces: {', '.join(f"{k}: {v}" for k, v in spaces.get('space_types', {}).items())}
        """
        
        for space in spaces.get("space_details", []):
            spaces_text += f"""
        - Espace '{space.get('name', 'Sans nom')}':
          Type: {space.get('type', 'Non dÃ©fini')}
          Surface: {space.get('area', 0):.2f} mÂ²
          Volume: {space.get('volume', 0):.2f} mÂ³
            """
        
        documents.append(Document(page_content=spaces_text, metadata={"type": "spaces"}))
        
        # Ouvertures
        openings = metrics.get("openings", {})
        openings_text = f"""
        Ouvertures du bÃ¢timent:
        - Nombre total de fenÃªtres: {openings.get('total_windows', 0)}
        - Nombre total de portes: {openings.get('total_doors', 0)}
        - Ratio fenÃªtres/murs: {openings.get('window_wall_ratio', 0):.3f}
        """
        documents.append(Document(page_content=openings_text, metadata={"type": "openings"}))
        
        # Ã‰lÃ©ments structurels
        structural = metrics.get("structural_elements", {})
        structural_text = f"""
        Ã‰lÃ©ments structurels:
        - Nombre de poutres: {structural.get('beams', 0)}
        - Nombre de colonnes: {structural.get('columns', 0)}
        - Nombre de murs: {structural.get('walls', 0)}
        - Nombre de dalles: {structural.get('slabs', 0)}
        - Nombre de fondations: {structural.get('foundations', 0)}
        """
        documents.append(Document(page_content=structural_text, metadata={"type": "structural"}))
        
        # MatÃ©riaux
        materials = metrics.get("materials", {})
        materials_text = f"""
        MatÃ©riaux utilisÃ©s:
        - Nombre total de matÃ©riaux: {materials.get('total_materials', 0)}
        - Liste des matÃ©riaux: {', '.join([mat.get('name', 'Sans nom') for mat in materials.get('material_list', [])])}
        """
        documents.append(Document(page_content=materials_text, metadata={"type": "materials"}))
        
        # Anomalies
        anomalies_data = self.current_ifc_data.get("anomalies", {})
        anomaly_summary = anomalies_data.get("summary", {})
        anomalies_text = f"""
        Anomalies dÃ©tectÃ©es:
        - Nombre total d'anomalies: {anomaly_summary.get('total_anomalies', 0)}
        - Anomalies critiques: {anomaly_summary.get('by_severity', {}).get('critical', 0)}
        - Anomalies importantes: {anomaly_summary.get('by_severity', {}).get('high', 0)}
        - Anomalies moyennes: {anomaly_summary.get('by_severity', {}).get('medium', 0)}
        - Anomalies mineures: {anomaly_summary.get('by_severity', {}).get('low', 0)}
        - ProblÃ¨mes les plus frÃ©quents: {', '.join([f"{issue[0]} ({issue[1]})" for issue in anomaly_summary.get('most_common_issues', [])])}
        """
        documents.append(Document(page_content=anomalies_text, metadata={"type": "anomalies"}))
        
        # CrÃ©er le vector store
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        
        split_documents = text_splitter.split_documents(documents)
        
        self.vectorstore = FAISS.from_documents(
            split_documents,
            self.embeddings
        )
        
        logger.info(f"Base de connaissances crÃ©Ã©e avec {len(split_documents)} chunks")
    
    def _create_qa_chain(self):
        """CrÃ©e la chaÃ®ne de question-rÃ©ponse"""
        if not self.vectorstore:
            raise ValueError("Base de connaissances non crÃ©Ã©e")
        
        self.qa_chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.vectorstore.as_retriever(search_kwargs={"k": 5}),
            memory=self.memory,
            return_source_documents=True,
            verbose=True
        )
    
    def ask_question(self, question: str) -> Dict[str, Any]:
        """
        Pose une question sur le modÃ¨le IFC chargÃ©
        
        Args:
            question: Question de l'utilisateur
            
        Returns:
            Dictionnaire avec la rÃ©ponse et les mÃ©tadonnÃ©es
        """
        if not self.qa_chain:
            raise ValueError("Aucun modÃ¨le IFC chargÃ© ou chaÃ®ne Q&A non initialisÃ©e")
        
        try:
            # Enrichir la question avec le contexte BIM
            enriched_question = f"""
            {self.bim_context}
            
            Fichier IFC analysÃ©: {Path(self.current_file_path).name if self.current_file_path else 'Non dÃ©fini'}
            
            Question de l'utilisateur: {question}
            
            RÃ©pondez en utilisant les donnÃ©es du modÃ¨le IFC chargÃ©. Si l'information n'est pas disponible dans les donnÃ©es,
            dites-le clairement et proposez des analyses complÃ©mentaires si pertinent.
            """
            
            # Obtenir la rÃ©ponse
            result = self.qa_chain({"question": enriched_question})
            
            response = {
                "answer": result["answer"],
                "source_documents": [
                    {
                        "content": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
                        "metadata": doc.metadata
                    }
                    for doc in result.get("source_documents", [])
                ],
                "question": question,
                "file_analyzed": Path(self.current_file_path).name if self.current_file_path else None
            }
            
            return response
            
        except Exception as e:
            logger.error(f"Erreur lors du traitement de la question: {e}")
            raise
    
    def get_suggested_questions(self) -> List[str]:
        """Retourne une liste de questions suggÃ©rÃ©es basÃ©es sur le modÃ¨le chargÃ©"""
        if not self.current_ifc_data:
            return [
                "Chargez d'abord un fichier IFC pour obtenir des suggestions de questions."
            ]
        
        suggestions = [
            "Quelle est la surface totale habitable de ce bÃ¢timent ?",
            "Combien d'Ã©tages compte ce bÃ¢timent ?",
            "Quels sont les matÃ©riaux principaux utilisÃ©s ?",
            "Y a-t-il des anomalies dÃ©tectÃ©es dans ce modÃ¨le ?",
            "Quel est le ratio fenÃªtres/murs de ce bÃ¢timent ?",
            "Combien d'espaces diffÃ©rents sont dÃ©finis ?",
            "Quels sont les Ã©lÃ©ments structurels principaux ?",
            "Y a-t-il des problÃ¨mes de connectivitÃ© entre les Ã©lÃ©ments ?",
            "Quelle est la complexitÃ© de ce modÃ¨le BIM ?",
            "Ce bÃ¢timent respecte-t-il les bonnes pratiques BIM ?"
        ]
        
        # Ajouter des suggestions spÃ©cifiques basÃ©es sur les donnÃ©es
        metrics = self.current_ifc_data.get("building_metrics", {})
        
        if metrics.get("anomalies", {}).get("summary", {}).get("total_anomalies", 0) > 0:
            suggestions.append("Quelles sont les anomalies les plus critiques ?")
        
        if metrics.get("spaces", {}).get("total_spaces", 0) > 10:
            suggestions.append("Pouvez-vous analyser la rÃ©partition des espaces ?")
        
        if metrics.get("storeys", {}).get("total_storeys", 0) > 3:
            suggestions.append("Comment sont rÃ©partis les Ã©lÃ©ments par Ã©tage ?")
        
        return suggestions
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """Retourne l'historique de la conversation"""
        if not self.memory.chat_memory.messages:
            return []
        
        history = []
        messages = self.memory.chat_memory.messages
        
        for i in range(0, len(messages), 2):
            if i + 1 < len(messages):
                history.append({
                    "question": messages[i].content,
                    "answer": messages[i + 1].content,
                    "timestamp": getattr(messages[i], 'timestamp', None)
                })
        
        return history
    
    def clear_conversation(self):
        """Efface l'historique de la conversation"""
        self.memory.clear()
        logger.info("Historique de conversation effacÃ©")
    
    def get_model_summary(self) -> Dict[str, Any]:
        """Retourne un rÃ©sumÃ© du modÃ¨le actuellement chargÃ©"""
        if not self.current_ifc_data:
            return {"status": "no_model_loaded"}
        
        project_info = self.current_ifc_data.get("project_info", {})
        metrics = self.current_ifc_data.get("building_metrics", {})
        anomalies = self.current_ifc_data.get("anomalies", {}).get("summary", {})
        
        return {
            "status": "model_loaded",
            "file_path": self.current_file_path,
            "file_name": Path(self.current_file_path).name if self.current_file_path else None,
            "project_name": project_info.get("project_name"),
            "building_name": project_info.get("building_name"),
            "schema": project_info.get("schema"),
            "total_elements": project_info.get("total_elements"),
            "file_size_mb": project_info.get("file_size_mb"),
            "key_metrics": {
                "total_floor_area": metrics.get("surfaces", {}).get("total_floor_area"),
                "total_storeys": metrics.get("storeys", {}).get("total_storeys"),
                "total_spaces": metrics.get("spaces", {}).get("total_spaces"),
                "total_anomalies": anomalies.get("total_anomalies"),
                "window_wall_ratio": metrics.get("openings", {}).get("window_wall_ratio")
            }
        }
    
    def generate_quick_insights(self) -> List[str]:
        """GÃ©nÃ¨re des insights rapides sur le modÃ¨le chargÃ©"""
        if not self.current_ifc_data:
            return ["Aucun modÃ¨le chargÃ©"]
        
        insights = []
        metrics = self.current_ifc_data.get("building_metrics", {})
        project_info = self.current_ifc_data.get("project_info", {})
        
        # Insights sur la taille
        floor_area = metrics.get("surfaces", {}).get("total_floor_area", 0)
        if floor_area > 0:
            if floor_area < 100:
                insights.append("ğŸ  Petit bÃ¢timent (< 100 mÂ²)")
            elif floor_area < 500:
                insights.append("ğŸ¢ BÃ¢timent de taille moyenne (100-500 mÂ²)")
            elif floor_area < 2000:
                insights.append("ğŸ¬ Grand bÃ¢timent (500-2000 mÂ²)")
            else:
                insights.append("ğŸ­ TrÃ¨s grand bÃ¢timent (> 2000 mÂ²)")
        
        # Insights sur les Ã©tages
        storeys = metrics.get("storeys", {}).get("total_storeys", 0)
        if storeys == 1:
            insights.append("ğŸ“ BÃ¢timent de plain-pied")
        elif storeys <= 3:
            insights.append(f"ğŸ˜ï¸ BÃ¢timent de {storeys} Ã©tages (faible hauteur)")
        else:
            insights.append(f"ğŸ—ï¸ BÃ¢timent de {storeys} Ã©tages (hauteur importante)")
        
        # Insights sur les anomalies
        total_anomalies = self.current_ifc_data.get("anomalies", {}).get("summary", {}).get("total_anomalies", 0)
        if total_anomalies == 0:
            insights.append("âœ… Aucune anomalie dÃ©tectÃ©e - ModÃ¨le de bonne qualitÃ©")
        elif total_anomalies < 5:
            insights.append("âš ï¸ Quelques anomalies mineures dÃ©tectÃ©es")
        else:
            insights.append(f"ğŸš¨ {total_anomalies} anomalies dÃ©tectÃ©es - RÃ©vision recommandÃ©e")
        
        # Insights sur la complexitÃ©
        total_elements = project_info.get("total_elements", 0)
        if total_elements < 100:
            insights.append("ğŸ”§ ModÃ¨le simple (< 100 Ã©lÃ©ments)")
        elif total_elements < 1000:
            insights.append("âš™ï¸ ModÃ¨le de complexitÃ© moyenne")
        else:
            insights.append("ğŸ”© ModÃ¨le complexe (> 1000 Ã©lÃ©ments)")
        
        return insights
