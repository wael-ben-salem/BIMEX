#!/usr/bin/env python3
"""
üß™ Script de V√©rification Finale des Dashboards Coh√©rents BIMEX
============================================================

Ce script v√©rifie que :
1. ‚úÖ Le backend retourne des donn√©es coh√©rentes
2. ‚úÖ Toutes les m√©triques sont synchronis√©es
3. ‚úÖ Les valeurs sont identiques entre les sections
4. ‚úÖ Aucune donn√©e factice n'est pr√©sente
"""

import requests
import json
from datetime import datetime
from typing import Dict, Any, List

class CoherentDashboardVerifier:
    def __init__(self, base_url: str = "http://localhost:8001"):
        self.base_url = base_url
        self.test_results = []
        
    def log_test(self, test_name: str, status: str, details: str = ""):
        """Enregistre le r√©sultat d'un test"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        result = {
            "timestamp": timestamp,
            "test": test_name,
            "status": status,
            "details": details
        }
        self.test_results.append(result)
        
        # Affichage color√©
        if status == "‚úÖ PASS":
            print(f"‚úÖ [{timestamp}] {test_name}: {details}")
        elif status == "‚ùå FAIL":
            print(f"‚ùå [{timestamp}] {test_name}: {details}")
        elif status == "‚ö†Ô∏è WARN":
            print(f"‚ö†Ô∏è [{timestamp}] {test_name}: {details}")
        else:
            print(f"‚ÑπÔ∏è [{timestamp}] {test_name}: {details}")
    
    def test_backend_endpoint(self, project_id: str = "BasicHouse") -> Dict[str, Any]:
        """Teste l'endpoint backend et retourne les donn√©es"""
        try:
            url = f"{self.base_url}/analytics/coherent-dashboard/{project_id}"
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                self.log_test("Backend Endpoint", "‚úÖ PASS", f"Donn√©es re√ßues: {len(data)} sections")
                return data
            else:
                self.log_test("Backend Endpoint", "‚ùå FAIL", f"Status: {response.status_code}")
                return {}
                
        except Exception as e:
            self.log_test("Backend Endpoint", "‚ùå FAIL", f"Erreur: {str(e)}")
            return {}
    
    def verify_bim_scores_coherence(self, data: Dict[str, Any]) -> bool:
        """V√©rifie la coh√©rence des scores BIM"""
        try:
            bim_scores = data.get("bim_scores", {})
            
            if not bim_scores:
                self.log_test("Scores BIM", "‚ùå FAIL", "Section bim_scores manquante")
                return False
            
            # V√©rifier que tous les scores sont pr√©sents
            required_scores = ["structural_score", "mep_score", "spatial_score", "quality_score"]
            missing_scores = [score for score in required_scores if score not in bim_scores]
            
            if missing_scores:
                self.log_test("Scores BIM", "‚ùå FAIL", f"Scores manquants: {missing_scores}")
                return False
            
            # V√©rifier que les scores sont dans la plage [0-100]
            for score_name, score_value in bim_scores.items():
                if not isinstance(score_value, (int, float)) or score_value < 0 or score_value > 100:
                    self.log_test("Scores BIM", "‚ùå FAIL", f"Score invalide {score_name}: {score_value}")
                    return False
            
            self.log_test("Scores BIM", "‚úÖ PASS", f"4 scores valides: {list(bim_scores.keys())}")
            return True
            
        except Exception as e:
            self.log_test("Scores BIM", "‚ùå FAIL", f"Erreur: {str(e)}")
            return False
    
    def verify_performance_metrics_coherence(self, data: Dict[str, Any]) -> bool:
        """V√©rifie la coh√©rence des m√©triques de performance"""
        try:
            performance_metrics = data.get("performance_metrics", {})
            
            if not performance_metrics:
                self.log_test("M√©triques Performance", "‚ùå FAIL", "Section performance_metrics manquante")
                return False
            
            # V√©rifier que toutes les m√©triques sont pr√©sentes
            required_metrics = ["efficiency", "sustainability", "cost_effectiveness", "innovation"]
            missing_metrics = [metric for metric in required_metrics if metric not in performance_metrics]
            
            if missing_metrics:
                self.log_test("M√©triques Performance", "‚ùå FAIL", f"M√©triques manquantes: {missing_metrics}")
                return False
            
            # V√©rifier que les valeurs sont coh√©rentes
            for metric_name, metric_value in performance_metrics.items():
                if not isinstance(metric_value, (int, float)) or metric_value < 0 or metric_value > 100:
                    self.log_test("M√©triques Performance", "‚ùå FAIL", f"M√©trique invalide {metric_name}: {metric_value}")
                    return False
            
            self.log_test("M√©triques Performance", "‚úÖ PASS", f"4 m√©triques valides: {list(performance_metrics.keys())}")
            return True
            
        except Exception as e:
            self.log_test("M√©triques Performance", "‚ùå FAIL", f"Erreur: {str(e)}")
            return False
    
    def verify_innovation_metrics_coherence(self, data: Dict[str, Any]) -> bool:
        """V√©rifie la coh√©rence des m√©triques d'innovation"""
        try:
            innovation_metrics = data.get("innovation_metrics", {})
            
            if not innovation_metrics:
                self.log_test("M√©triques Innovation", "‚ùå FAIL", "Section innovation_metrics manquante")
                return False
            
            # V√©rifier que toutes les m√©triques sont pr√©sentes
            required_metrics = ["ai_efficiency", "design_variants", "design_score", "maintenance_accuracy", "maintenance_savings", "innovation_score"]
            missing_metrics = [metric for metric in required_metrics if metric not in innovation_metrics]
            
            if missing_metrics:
                self.log_test("M√©triques Innovation", "‚ùå FAIL", f"M√©triques manquantes: {missing_metrics}")
                return False
            
            # V√©rifier les types et valeurs
            for metric_name, metric_value in innovation_metrics.items():
                if metric_name == "maintenance_savings":
                    if not isinstance(metric_value, str):
                        self.log_test("M√©triques Innovation", "‚ùå FAIL", f"maintenance_savings doit √™tre une string: {metric_value}")
                        return False
                elif metric_name == "design_variants":
                    if not isinstance(metric_value, int) or metric_value < 0:
                        self.log_test("M√©triques Innovation", "‚ùå FAIL", f"design_variants doit √™tre un entier positif: {metric_value}")
                        return False
                else:
                    if not isinstance(metric_value, (int, float)) or metric_value < 0 or metric_value > 100:
                        self.log_test("M√©triques Innovation", "‚ùå FAIL", f"M√©trique invalide {metric_name}: {metric_value}")
                        return False
            
            self.log_test("M√©triques Innovation", "‚úÖ PASS", f"6 m√©triques valides: {list(innovation_metrics.keys())}")
            return True
            
        except Exception as e:
            self.log_test("M√©triques Innovation", "‚ùå FAIL", f"Erreur: {str(e)}")
            return False
    
    def verify_element_counts_coherence(self, data: Dict[str, Any]) -> bool:
        """V√©rifie la coh√©rence des comptages d'√©l√©ments"""
        try:
            structural_elements = data.get("structural_elements", {})
            mep_elements = data.get("mep_elements", {})
            spatial_elements = data.get("spatial_elements", {})
            
            # V√©rifier les √©l√©ments structurels
            if structural_elements:
                required_elements = ["columns", "beams", "walls", "slabs"]
                for element in required_elements:
                    if element in structural_elements:
                        value = structural_elements[element]
                        if not isinstance(value, int) or value < 0:
                            self.log_test("√âl√©ments Structurels", "‚ùå FAIL", f"Valeur invalide pour {element}: {value}")
                            return False
                
                self.log_test("√âl√©ments Structurels", "‚úÖ PASS", f"√âl√©ments valides: {list(structural_elements.keys())}")
            
            # V√©rifier les √©l√©ments MEP
            if mep_elements:
                required_elements = ["electrical", "plumbing", "hvac", "fire_protection"]
                for element in required_elements:
                    if element in mep_elements:
                        value = mep_elements[element]
                        if not isinstance(value, int) or value < 0:
                            self.log_test("√âl√©ments MEP", "‚ùå FAIL", f"Valeur invalide pour {element}: {value}")
                            return False
                
                self.log_test("√âl√©ments MEP", "‚úÖ PASS", f"√âl√©ments valides: {list(mep_elements.keys())}")
            
            # V√©rifier les √©l√©ments spatiaux
            if spatial_elements:
                required_elements = ["spaces", "total_area", "total_volume", "storeys"]
                for element in required_elements:
                    if element in spatial_elements:
                        value = spatial_elements[element]
                        if not isinstance(value, (int, float)) or value < 0:
                            self.log_test("√âl√©ments Spatiaux", "‚ùå FAIL", f"Valeur invalide pour {element}: {value}")
                            return False
                
                self.log_test("√âl√©ments Spatiaux", "‚úÖ PASS", f"√âl√©ments valides: {list(spatial_elements.keys())}")
            
            return True
            
        except Exception as e:
            self.log_test("√âl√©ments", "‚ùå FAIL", f"Erreur: {str(e)}")
            return False
    
    def verify_no_dummy_data(self, data: Dict[str, Any]) -> bool:
        """V√©rifie qu'aucune donn√©e factice n'est pr√©sente"""
        try:
            # V√©rifier qu'il n'y a pas de valeurs √©videntes de test
            suspicious_values = ["--", "N/A", "null", "undefined", "test", "dummy", "placeholder"]
            
            data_str = json.dumps(data, default=str).lower()
            
            for suspicious in suspicious_values:
                if suspicious in data_str:
                    self.log_test("Donn√©es Factices", "‚ùå FAIL", f"Valeur suspecte d√©tect√©e: {suspicious}")
                    return False
            
            # V√©rifier qu'il n'y a pas de valeurs Math.random() √©videntes
            if "math.random" in data_str:
                self.log_test("Donn√©es Factices", "‚ùå FAIL", "Math.random() d√©tect√© dans les donn√©es")
                return False
            
            self.log_test("Donn√©es Factices", "‚úÖ PASS", "Aucune donn√©e factice d√©tect√©e")
            return True
            
        except Exception as e:
            self.log_test("Donn√©es Factices", "‚ùå FAIL", f"Erreur: {str(e)}")
            return False
    
    def verify_data_consistency(self, data: Dict[str, Any]) -> bool:
        """V√©rifie la coh√©rence globale des donn√©es"""
        try:
            # V√©rifier que les scores BIM et les m√©triques de performance sont coh√©rents
            bim_scores = data.get("bim_scores", {})
            performance_metrics = data.get("performance_metrics", {})
            
            if bim_scores and performance_metrics:
                # Les scores BIM et les m√©triques de performance doivent avoir des valeurs similaires
                bim_avg = sum(bim_scores.values()) / len(bim_scores)
                perf_avg = sum(performance_metrics.values()) / len(performance_metrics)
                
                # La diff√©rence ne doit pas √™tre trop importante (tol√©rance de 20%)
                if abs(bim_avg - perf_avg) > 20:
                    self.log_test("Coh√©rence Globale", "‚ö†Ô∏è WARN", f"Diff√©rence importante entre scores BIM ({bim_avg:.1f}) et performance ({perf_avg:.1f})")
                else:
                    self.log_test("Coh√©rence Globale", "‚úÖ PASS", f"Scores BIM ({bim_avg:.1f}) et performance ({perf_avg:.1f}) coh√©rents")
            
            # V√©rifier la source des donn√©es
            source = data.get("source", "unknown")
            last_updated = data.get("last_updated", "unknown")
            
            self.log_test("Source Donn√©es", "‚ÑπÔ∏è INFO", f"Source: {source}, Derni√®re mise √† jour: {last_updated}")
            
            return True
            
        except Exception as e:
            self.log_test("Coh√©rence Globale", "‚ùå FAIL", f"Erreur: {str(e)}")
            return False
    
    def run_complete_verification(self, project_id: str = "BasicHouse") -> Dict[str, Any]:
        """Lance la v√©rification compl√®te des dashboards"""
        print("üß™ V√âRIFICATION COMPL√àTE DES DASHBOARDS COH√âRENTS BIMEX")
        print("=" * 70)
        print(f"üéØ Projet: {project_id}")
        print(f"üåê Backend: {self.base_url}")
        print(f"‚è∞ D√©but: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 70)
        
        # Test 1: Endpoint backend
        data = self.test_backend_endpoint(project_id)
        if not data:
            self.log_test("V√âRIFICATION GLOBALE", "‚ùå FAIL", "Impossible de r√©cup√©rer les donn√©es du backend")
            return self.generate_report()
        
        # Test 2: V√©rification des scores BIM
        self.verify_bim_scores_coherence(data)
        
        # Test 3: V√©rification des m√©triques de performance
        self.verify_performance_metrics_coherence(data)
        
        # Test 4: V√©rification des m√©triques d'innovation
        self.verify_innovation_metrics_coherence(data)
        
        # Test 5: V√©rification des comptages d'√©l√©ments
        self.verify_element_counts_coherence(data)
        
        # Test 6: V√©rification des donn√©es factices
        self.verify_no_dummy_data(data)
        
        # Test 7: V√©rification de la coh√©rence globale
        self.verify_data_consistency(data)
        
        # R√©sum√© final
        total_tests = len(self.test_results)
        passed_tests = len([r for r in self.test_results if r["status"] == "‚úÖ PASS"])
        failed_tests = len([r for r in self.test_results if r["status"] == "‚ùå FAIL"])
        warnings = len([r for r in self.test_results if r["status"] == "‚ö†Ô∏è WARN"])
        
        print("\n" + "=" * 70)
        print("üìä R√âSULTATS DE LA V√âRIFICATION")
        print("=" * 70)
        print(f"‚úÖ Tests r√©ussis: {passed_tests}")
        print(f"‚ùå Tests √©chou√©s: {failed_tests}")
        print(f"‚ö†Ô∏è Avertissements: {warnings}")
        print(f"üìä Total: {total_tests}")
        
        if failed_tests == 0:
            print("\nüéâ TOUS LES TESTS SONT PASS√âS ! Les dashboards sont parfaitement coh√©rents !")
            overall_status = "‚úÖ SUCCESS"
        elif failed_tests <= warnings:
            print("\n‚ö†Ô∏è Quelques avertissements mais pas d'erreurs critiques")
            overall_status = "‚ö†Ô∏è WARNING"
        else:
            print("\n‚ùå Des erreurs critiques ont √©t√© d√©tect√©es")
            overall_status = "‚ùå FAILED"
        
        self.log_test("V√âRIFICATION GLOBALE", overall_status, f"R√©sultat: {passed_tests}/{total_tests} tests r√©ussis")
        
        return self.generate_report()
    
    def generate_report(self) -> Dict[str, Any]:
        """G√©n√®re un rapport d√©taill√© de la v√©rification"""
        return {
            "timestamp": datetime.now().isoformat(),
            "base_url": self.base_url,
            "test_results": self.test_results,
            "summary": {
                "total": len(self.test_results),
                "passed": len([r for r in self.test_results if r["status"] == "‚úÖ PASS"]),
                "failed": len([r for r in self.test_results if r["status"] == "‚ùå FAIL"]),
                "warnings": len([r for r in self.test_results if r["status"] == "‚ö†Ô∏è WARN"])
            }
        }

def main():
    """Fonction principale"""
    print("üöÄ Lancement de la v√©rification des dashboards coh√©rents...")
    
    # Cr√©er le v√©rificateur
    verifier = CoherentDashboardVerifier("http://localhost:8001")
    
    # Lancer la v√©rification compl√®te
    try:
        report = verifier.run_complete_verification("BasicHouse")
        
        # Sauvegarder le rapport
        with open("verification_report.json", "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìÑ Rapport sauvegard√© dans: verification_report.json")
        
        # Afficher le statut final
        if report["summary"]["failed"] == 0:
            print("\nüéØ MISSION ACCOMPLIE ! Tous les dashboards sont parfaitement coh√©rents !")
            return 0
        else:
            print(f"\n‚ö†Ô∏è {report['summary']['failed']} erreur(s) d√©tect√©e(s) - V√©rification n√©cessaire")
            return 1
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è V√©rification interrompue par l'utilisateur")
        return 1
    except Exception as e:
        print(f"\nüí• Erreur critique: {str(e)}")
        return 1

if __name__ == "__main__":
    exit(main())


